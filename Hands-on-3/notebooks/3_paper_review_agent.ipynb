{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: AI Paper Review Agent í™œìš©í•˜ê¸°\n",
    "\n",
    "**SNU AI Psychology Workshop - February 2026**\n",
    "\n",
    "---\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "1. ê¸°ì¡´ ì˜¤í”ˆì†ŒìŠ¤ **Paper Review Agent** ë„êµ¬ë“¤ ì•Œì•„ë³´ê¸°\n",
    "2. **agentic-paper-review** ì„¤ì¹˜ ë° ì‹¤í–‰\n",
    "3. ë³¸ì¸ ë…¼ë¬¸ìœ¼ë¡œ AI ë¦¬ë·° ë°›ì•„ë³´ê¸°\n",
    "\n",
    "---\n",
    "\n",
    "## ê¸°ì¡´ ì˜¤í”ˆì†ŒìŠ¤ ë„êµ¬ë“¤\n",
    "\n",
    "| ë„êµ¬ | íŠ¹ì§• | GitHub |\n",
    "|------|------|--------|\n",
    "| **agentic-paper-review** | LangGraph 9ë…¸ë“œ, Ï=0.74 | [debashis1983/agentic-paper-review](https://github.com/debashis1983/agentic-paper-review) |\n",
    "| **AgentReview** | ë‹¤ì¤‘ ì—ì´ì „íŠ¸, ë¦¬ë·°ì–´ ì„±ê²© ì‹œë®¬ë ˆì´ì…˜ | [Ahren09/AgentReview](https://github.com/Ahren09/AgentReview) |\n",
    "| **AI-Scientist** | ì „ì²´ ì—°êµ¬ íŒŒì´í”„ë¼ì¸ | [SakanaAI/AI-Scientist](https://github.com/SakanaAI/AI-Scientist) |\n",
    "\n",
    "ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” **agentic-paper-review**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Setup\n",
    "\n",
    "### API Key ë°œê¸‰ ë§í¬\n",
    "\n",
    "| API | ë§í¬ | ë¹„ê³  |\n",
    "|-----|------|------|\n",
    "| **OpenAI** (í•„ìˆ˜) | https://platform.openai.com/api-keys | agentic-paper-reviewì— í•„ìš” |\n",
    "| **Gemini** (ëŒ€ì•ˆ) | https://aistudio.google.com/apikey | ë¬´ë£Œ, ë„‰ë„‰í•œ quota |\n",
    "\n",
    "> âš ï¸ **agentic-paper-review**ëŠ” OpenAI APIê°€ í•„ìš”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: í™˜ê²½ ì„¤ì •\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Colab í™˜ê²½ ê°ì§€\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    WORKSHOP_DIR = \"/content/drive/MyDrive/Hands-on-3/\"\n",
    "    os.makedirs(WORKSHOP_DIR, exist_ok=True)\n",
    "    os.chdir(WORKSHOP_DIR)\n",
    "    IN_COLAB = True\n",
    "    print(\"ğŸŒ Colab í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\n",
    "except ImportError:\n",
    "    current_dir = os.getcwd()\n",
    "    if current_dir.endswith('notebooks'):\n",
    "        os.chdir('..')\n",
    "    WORKSHOP_DIR = os.getcwd()\n",
    "    IN_COLAB = False\n",
    "    print(\"ğŸ’» ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\n",
    "\n",
    "print(f\"ì‘ì—… í´ë”: {WORKSHOP_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: agentic-paper-review ì„¤ì¹˜\nimport os\nimport urllib.request\nimport shutil\n\nAGENT_DIR = os.path.join(WORKSHOP_DIR, \"agentic-paper-review\")\n\n# Colab: ê¸°ì¡´ í´ë” ì‚­ì œ í›„ ìƒˆë¡œ ì„¤ì¹˜ (ìµœì‹  ë²„ì „ ë³´ì¥)\nif IN_COLAB and os.path.exists(AGENT_DIR):\n    print(\"ğŸ—‘ï¸ ê¸°ì¡´ agentic-paper-review ì‚­ì œ ì¤‘...\")\n    shutil.rmtree(AGENT_DIR)\n\nif not os.path.exists(AGENT_DIR):\n    print(\"ğŸ“¥ agentic-paper-review í´ë¡  ì¤‘...\")\n    !git clone https://github.com/debashis1983/agentic-paper-review.git {AGENT_DIR}\n    print(\"âœ… í´ë¡  ì™„ë£Œ!\")\nelse:\n    print(f\"âœ… ì´ë¯¸ ì„¤ì¹˜ë¨: {AGENT_DIR}\")\n\n# Gemini ì§€ì› agent.pyë¡œ êµì²´ (ì›Œí¬ìƒµìš© ìˆ˜ì • ë²„ì „)\nprint(\"\\nğŸ”„ Gemini ì§€ì› ë²„ì „ìœ¼ë¡œ ì—…ë°ì´íŠ¸ ì¤‘...\")\nagent_url = \"https://raw.githubusercontent.com/yoonlee78/2026_SNUIPS_AI_Workshop/master/Hands-on-3/lib/agent_gemini.py\"\nagent_path = os.path.join(AGENT_DIR, \"agent.py\")\ntry:\n    urllib.request.urlretrieve(agent_url, agent_path)\n    print(\"âœ… Gemini ì§€ì› agent.py ì ìš© ì™„ë£Œ!\")\nexcept Exception as e:\n    print(f\"âš ï¸ agent.py ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}\")\n    print(\"   (ì›ë³¸ ë²„ì „ ì‚¬ìš© - OpenAI API í•„ìš”)\")\n\n# ì˜ì¡´ì„± ì„¤ì¹˜ (langchain-google-genai ì¶”ê°€ - Gemini APIìš©)\nprint(\"\\nğŸ“¦ ì˜ì¡´ì„± ì„¤ì¹˜ ì¤‘...\")\n!pip install langgraph langchain langchain-openai langchain-anthropic langchain-google-genai pdfplumber tavily-python pymupdf -q\nprint(\"âœ… ì˜ì¡´ì„± ì„¤ì¹˜ ì™„ë£Œ!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: API Key ë¡œë”©\nimport os\n\n# âœï¸ ì‚¬ìš©í•  API ì„ íƒ (ì•„ë˜ ì¤‘ í•˜ë‚˜ë§Œ ì£¼ì„ í•´ì œ)\n# USE_API = \"openai\"   # OpenAI ì‚¬ìš© (agentic-paper-review ê¸°ë³¸)\nUSE_API = \"gemini\"   # Gemini ì‚¬ìš© (ë¬´ë£Œ)\n# USE_API = \"auto\"       # ìë™ ì„ íƒ (OpenAI ìš°ì„ )\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# API Key ë¡œë”©\nif IN_COLAB:\n    from google.colab import userdata\n    \n    # Gemini Key (ì—¬ëŸ¬ ì´ë¦„ ì‹œë„)\n    GEMINI_API_KEY = None\n    for key_name in ['GEMINI_API_KEY', 'gemini key', 'gemini_key', 'GOOGLE_API_KEY']:\n        try:\n            key = userdata.get(key_name)\n            if key:\n                GEMINI_API_KEY = key\n                break\n        except:\n            pass\n    \n    # OpenAI Key (ì—¬ëŸ¬ ì´ë¦„ ì‹œë„)\n    OPENAI_API_KEY = None\n    for key_name in ['OPENAI_API_KEY', 'openai key', 'openai_key']:\n        try:\n            key = userdata.get(key_name)\n            if key:\n                OPENAI_API_KEY = key\n                break\n        except:\n            pass\nelse:\n    from dotenv import load_dotenv\n    load_dotenv(override=True)\n    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n    GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# ëª¨ë“  í‚¤ë¥¼ os.environì— ì„¤ì • (agentic-paper-reviewê°€ ë‚´ë¶€ì ìœ¼ë¡œ í•„ìš”)\nif OPENAI_API_KEY and not OPENAI_API_KEY.startswith('your_'):\n    os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\nif GEMINI_API_KEY and not GEMINI_API_KEY.startswith('your_'):\n    os.environ['GOOGLE_API_KEY'] = GEMINI_API_KEY\n    os.environ['GEMINI_API_KEY'] = GEMINI_API_KEY\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# API ì„ íƒ ë¡œì§ (í‘œì‹œìš©)\nAPI_PROVIDER = None\n\nif USE_API == \"openai\":\n    if OPENAI_API_KEY and not OPENAI_API_KEY.startswith('your_'):\n        API_PROVIDER = 'openai'\n        print(\"âœ… OpenAI API ì‚¬ìš©\")\n    else:\n        print(\"âŒ OpenAI API Keyê°€ ì—†ìŠµë‹ˆë‹¤\")\n\nelif USE_API == \"gemini\":\n    if GEMINI_API_KEY and not GEMINI_API_KEY.startswith('your_'):\n        API_PROVIDER = 'gemini'\n        print(\"âœ… Gemini API ì‚¬ìš©\")\n    else:\n        print(\"âŒ Gemini API Keyê°€ ì—†ìŠµë‹ˆë‹¤\")\n        if IN_COLAB:\n            print(\"   Colab: ì¢Œì¸¡ ğŸ”‘ > GEMINI_API_KEY ë˜ëŠ” 'gemini key' ì¶”ê°€\")\n        else:\n            print(\"   ë¡œì»¬: .env íŒŒì¼ì— GEMINI_API_KEY ì¶”ê°€\")\n\nelse:  # auto\n    if OPENAI_API_KEY and not OPENAI_API_KEY.startswith('your_'):\n        API_PROVIDER = 'openai'\n        print(\"âœ… OpenAI API ì‚¬ìš© (ìë™)\")\n    elif GEMINI_API_KEY and not GEMINI_API_KEY.startswith('your_'):\n        API_PROVIDER = 'gemini'\n        print(\"âœ… Gemini API ì‚¬ìš© (ìë™)\")\n\nif API_PROVIDER is None:\n    print(\"âŒ API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤!\")\n    if IN_COLAB:\n        print(\"   Colab: ì¢Œì¸¡ ğŸ”‘ ì•„ì´ì½˜ > Secretsì— í‚¤ ì¶”ê°€\")\n    else:\n        print(\"   ë¡œì»¬: .env íŒŒì¼ì— í‚¤ ì¶”ê°€\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: agentic-paper-review ì†Œê°œ\n",
    "\n",
    "### ì•„í‚¤í…ì²˜\n",
    "\n",
    "**9-Node LangGraph Workflow:**\n",
    "```\n",
    "[1. PDFâ†’MD] â†’ [2. ë©”íƒ€ë°ì´í„°] â†’ [3. ì¿¼ë¦¬ìƒì„±] â†’ [4. ì›¹ê²€ìƒ‰]\n",
    "      â†“\n",
    "[5. ê´€ë ¨ì„±í‰ê°€] â†’ [6. ë¦¬í”Œë ‰ì…˜] â†’ [7. ìš”ì•½] â†’ [8. ë¦¬ë·°ìƒì„±] â†’ [9. ì ìˆ˜ì‚°ì •]\n",
    "```\n",
    "\n",
    "> ğŸ’¡ **MD/TXT íŒŒì¼**: 1ë²ˆ ë…¸ë“œ ìŠ¤í‚µ â†’ ë°”ë¡œ 2ë²ˆë¶€í„° ì‹œì‘\n",
    "> ğŸ’¡ **DOCX íŒŒì¼**: í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ 2ë²ˆë¶€í„° ì‹œì‘\n",
    "\n",
    "### í‰ê°€ ì°¨ì›\n",
    "- **Soundness**: ë°©ë²•ë¡ ì˜ ì—„ë°€ì„±\n",
    "- **Presentation**: ë…¼ë¬¸ì˜ ëª…í™•ì„±\n",
    "- **Contribution**: ê¸°ì—¬ë„\n",
    "\n",
    "### ì„±ëŠ¥\n",
    "- Spearman Ï = 0.74 (46,748ê°œ ì‹¤ì œ ë¦¬ë·°ë¡œ í•™ìŠµ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 4: ë…¼ë¬¸ ë¡œë”© (PDF, MD, TXT, DOCX ëª¨ë‘ ì§€ì›)\nimport os\n\n# âœï¸ ë³¸ì¸ ë…¼ë¬¸ ê²½ë¡œ ì…ë ¥ (my_manuscript.mdê°€ ìˆìœ¼ë©´ ìë™ ì‚¬ìš©)\nMY_PAPER_PATH = \"input/my_manuscript.md\"  # ë˜ëŠ” ë‹¤ë¥¸ íŒŒì¼ ê²½ë¡œ\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nPAPER_PATH = None\nPAPER_TEXT = None  # MD/TXT/DOCXì¸ ê²½ìš° í…ìŠ¤íŠ¸ ì €ì¥\n\n# 1ìˆœìœ„: ë³¸ì¸ ë…¼ë¬¸\nif MY_PAPER_PATH and os.path.exists(MY_PAPER_PATH):\n    PAPER_PATH = MY_PAPER_PATH\n    ext = os.path.splitext(MY_PAPER_PATH)[1].lower()\n\n    if ext == '.pdf':\n        print(f\"âœ… PDF ë…¼ë¬¸: {MY_PAPER_PATH}\")\n    elif ext in ['.md', '.txt']:\n        with open(MY_PAPER_PATH, 'r', encoding='utf-8') as f:\n            PAPER_TEXT = f.read()\n        print(f\"âœ… í…ìŠ¤íŠ¸ ë…¼ë¬¸: {MY_PAPER_PATH} (1ë²ˆ ë…¸ë“œ ìŠ¤í‚µ)\")\n    elif ext in ['.docx', '.doc']:\n        try:\n            import docx\n            doc = docx.Document(MY_PAPER_PATH)\n            PAPER_TEXT = \"\\n\".join([para.text for para in doc.paragraphs])\n            print(f\"âœ… Word ë…¼ë¬¸: {MY_PAPER_PATH} (1ë²ˆ ë…¸ë“œ ìŠ¤í‚µ)\")\n        except ImportError:\n            print(\"âš ï¸ python-docx í•„ìš”: pip install python-docx\")\n\n# 2ìˆœìœ„: ìƒ˜í”Œ ë…¼ë¬¸\nif PAPER_PATH is None:\n    SAMPLE_PATH = os.path.join(WORKSHOP_DIR, \"input\", \"sample_manuscript.md\")\n\n    # Colab: ìƒ˜í”Œ íŒŒì¼ì´ ì—†ìœ¼ë©´ GitHubì—ì„œ ë‹¤ìš´ë¡œë“œ\n    if not os.path.exists(SAMPLE_PATH):\n        os.makedirs(os.path.dirname(SAMPLE_PATH), exist_ok=True)\n        print(\"ğŸ“¥ ìƒ˜í”Œ ë…¼ë¬¸ ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n        import urllib.request\n        url = \"https://raw.githubusercontent.com/yoonlee78/2026_SNUIPS_AI_Workshop/master/Hands-on-3/input/sample_manuscript.md\"\n        urllib.request.urlretrieve(url, SAMPLE_PATH)\n        print(\"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")\n\n    if os.path.exists(SAMPLE_PATH):\n        PAPER_PATH = SAMPLE_PATH\n        with open(SAMPLE_PATH, 'r', encoding='utf-8') as f:\n            PAPER_TEXT = f.read()\n        print(f\"ğŸ“„ ìƒ˜í”Œ ë…¼ë¬¸ ì‚¬ìš© ì¤‘ (1ë²ˆ ë…¸ë“œ ìŠ¤í‚µ)\")\n        print(\"\")\n        print(\"=\"*50)\n        print(\"âš ï¸ ë³¸ì¸ ë…¼ë¬¸ìœ¼ë¡œ ì‹¤ìŠµí•˜ë ¤ë©´:\")\n        print(\"   MY_PAPER_PATHì— íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”\")\n        print(\"   ì§€ì› í˜•ì‹: PDF, MD, TXT, DOCX\")\n        print(\"=\"*50)\n\nif PAPER_PATH:\n    print(f\"\\nğŸ“„ ë…¼ë¬¸ ê²½ë¡œ: {PAPER_PATH}\")\n    if PAPER_TEXT:\n        print(f\"   í…ìŠ¤íŠ¸ ê¸¸ì´: {len(PAPER_TEXT)} ë¬¸ì\")\nelse:\n    print(\"âŒ ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n    print(\"   MY_PAPER_PATHì— ë³¸ì¸ ë…¼ë¬¸ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: agentic-paper-review ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 5: agentic-paper-review ëª¨ë“ˆ ë¡œë”©\nimport sys\n\n# Colab: ê¸°ì¡´ì— ë¡œë“œëœ ëª¨ë“ˆ ì œê±° (ìƒˆ ë²„ì „ ê°•ì œ ì ìš©)\nif IN_COLAB:\n    modules_to_remove = [key for key in sys.modules.keys() if 'agent' in key.lower()]\n    for mod in modules_to_remove:\n        del sys.modules[mod]\n    print(\"ğŸ”„ Colab: ëª¨ë“ˆ ìºì‹œ ì´ˆê¸°í™”\")\n\n# ê²½ë¡œ ì¶”ê°€ (ì´ë¯¸ ìˆìœ¼ë©´ ì œì™¸)\nif AGENT_DIR not in sys.path:\n    sys.path.insert(0, AGENT_DIR)\n\n# API Key ì„¤ì • í™•ì¸ (ëª¨ë“ˆ import ì „)\nprint(f\"\\nğŸ”‘ API Key ìƒíƒœ:\")\nprint(f\"   GOOGLE_API_KEY: {'âœ… ì„¤ì •ë¨' if os.getenv('GOOGLE_API_KEY') else 'âŒ ì—†ìŒ'}\")\nprint(f\"   OPENAI_API_KEY: {'âœ… ì„¤ì •ë¨' if os.getenv('OPENAI_API_KEY') else 'âŒ ì—†ìŒ'}\")\n\ntry:\n    from agent import AgenticPaperReviewer\n    print(\"\\nâœ… AgenticPaperReviewer ë¡œë”© ì™„ë£Œ\")\nexcept ImportError as e:\n    print(f\"\\nâš ï¸ ëª¨ë“ˆ ë¡œë”© ì‹¤íŒ¨: {e}\")\n    print(\"   Cell 2ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš” (ì„¤ì¹˜)\")\nexcept Exception as e:\n    print(f\"\\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\")\n    import traceback\n    traceback.print_exc()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 6: ë¦¬ë·° ì‹¤í–‰\n# agentic-paper-reviewëŠ” paper_content íŒŒë¼ë¯¸í„°ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë°›ìœ¼ë©´\n# ìë™ìœ¼ë¡œ pdf_to_markdown ë…¸ë“œë¥¼ ìŠ¤í‚µí•©ë‹ˆë‹¤!\n\nif PAPER_PATH:\n    print(f\"ğŸ”„ ë…¼ë¬¸ ë¦¬ë·° ì‹œì‘: {PAPER_PATH}\")\n    if PAPER_TEXT:\n        print(\"   (í…ìŠ¤íŠ¸ ì…ë ¥ â†’ 1ë²ˆ ë…¸ë“œ ìŠ¤í‚µ)\")\n    print(\"   (1-2ë¶„ ì†Œìš”)\")\n    print(\"=\"*60)\n    \n    # ë¦¬ë·° ì‹¤í–‰ ì „ API í‚¤ ìµœì¢… í™•ì¸\n    print(f\"\\nğŸ“¡ API ì„¤ì • ìµœì¢… í™•ì¸:\")\n    print(f\"   GOOGLE_API_KEY: {os.getenv('GOOGLE_API_KEY', '')[:15]}...\" if os.getenv('GOOGLE_API_KEY') else \"   GOOGLE_API_KEY: âŒ ì—†ìŒ\")\n    print(\"\")\n    \n    # ë¦¬ë·° ì‹¤í–‰\n    reviewer = AgenticPaperReviewer()\n    \n    try:\n        if PAPER_TEXT:\n            # í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ paper_contentë¡œ ì „ë‹¬ (1ë²ˆ ë…¸ë“œ ìŠ¤í‚µ)\n            review_result = await reviewer.review_paper(\n                paper_content=PAPER_TEXT,\n                target_venue=\"Psychology\"\n            )\n        else:\n            # PDFë©´ paper_pathë¡œ ì „ë‹¬ (ì „ì²´ ì›Œí¬í”Œë¡œìš°)\n            review_result = await reviewer.review_paper(\n                paper_path=PAPER_PATH,\n                target_venue=\"Psychology\"\n            )\n        \n        # ê²°ê³¼ ìƒíƒœ í™•ì¸\n        status = review_result.get('status', 'unknown')\n        errors = review_result.get('metadata', {}).get('errors', [])\n        \n        if status == 'complete' and review_result.get('review'):\n            print(\"\\nâœ… ë¦¬ë·° ì™„ë£Œ!\")\n        elif status == 'failed' or errors:\n            print(f\"\\nâš ï¸ ë¦¬ë·° ì‹¤íŒ¨ ë˜ëŠ” ë¶ˆì™„ì „\")\n            print(f\"   ìƒíƒœ: {status}\")\n            if errors:\n                print(f\"   ì—ëŸ¬: {errors}\")\n        else:\n            print(f\"\\nâš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ê²°ê³¼ (ìƒíƒœ: {status})\")\n            \n    except Exception as e:\n        print(f\"\\nâŒ ë¦¬ë·° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}\")\n        import traceback\n        traceback.print_exc()\n        review_result = None\nelse:\n    print(\"âŒ ë…¼ë¬¸ ê²½ë¡œë¥¼ ë¨¼ì € ì„¤ì •í•˜ì„¸ìš” (Cell 4)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: ê²°ê³¼ í™•ì¸\n",
    "if 'review_result' in dir() and review_result:\n",
    "    print(\"ğŸ“Š ë¦¬ë·° ê²°ê³¼\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # ìƒíƒœ í™•ì¸\n",
    "    print(f\"\\nìƒíƒœ: {review_result.get('status', 'unknown')}\")\n",
    "    \n",
    "    # ë…¼ë¬¸ ì •ë³´\n",
    "    metadata = review_result.get('paper_metadata')\n",
    "    if metadata:\n",
    "        print(f\"\\nğŸ“„ ë…¼ë¬¸: {metadata.get('title', 'Unknown')}\")\n",
    "    \n",
    "    # ì ìˆ˜ ì¶œë ¥\n",
    "    scores = review_result.get('scores', {})\n",
    "    if scores.get('dimensions'):\n",
    "        print(\"\\nğŸ“ˆ ì ìˆ˜:\")\n",
    "        for dim in scores['dimensions']:\n",
    "            print(f\"  {dim['name']}: {dim['score']} - {dim['justification'][:50]}...\")\n",
    "    \n",
    "    if scores.get('final_score'):\n",
    "        print(f\"\\nğŸ¯ ìµœì¢… ì ìˆ˜: {scores['final_score_display']}\")\n",
    "    \n",
    "    # ë¦¬ë·° ì¶œë ¥\n",
    "    review = review_result.get('review', '')\n",
    "    if review:\n",
    "        print(\"\\nğŸ“‹ ë¦¬ë·°:\")\n",
    "        print(\"=\"*60)\n",
    "        print(review[:3000])  # ì²˜ìŒ 3000ìë§Œ\n",
    "        if len(review) > 3000:\n",
    "            print(f\"\\n... ({len(review)}ì ì¤‘ 3000ìë§Œ í‘œì‹œ)\")\n",
    "    \n",
    "    # ê´€ë ¨ ì—°êµ¬\n",
    "    related = review_result.get('related_works', [])\n",
    "    if related:\n",
    "        print(f\"\\nğŸ“š ê´€ë ¨ ì—°êµ¬ ({len(related)}ê°œ):\")\n",
    "        for w in related[:5]:\n",
    "            print(f\"  - {w['title'][:50]}... (ê´€ë ¨ë„: {w['relevance']:.2f})\")\n",
    "    \n",
    "    # ì—ëŸ¬ í™•ì¸\n",
    "    errors = review_result.get('metadata', {}).get('errors', [])\n",
    "    if errors:\n",
    "        print(f\"\\nâš ï¸ ì—ëŸ¬: {errors}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"âš ï¸ Cell 6ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 7-1: ë¦¬ë·° í•œê¸€ ë²ˆì—­ (ì„ íƒ)\n# ============================================================\n# Trueë¡œ ì„¤ì •í•˜ë©´ ë¦¬ë·°ë¥¼ í•œê¸€ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤ (Gemini API ì‚¬ìš©)\n# ============================================================\n\nTRANSLATE_TO_KOREAN = False  # Trueë¡œ ë³€ê²½í•˜ë©´ ë²ˆì—­ ì‹¤í–‰\n\n# ============================================================\n\nif TRANSLATE_TO_KOREAN:\n    if 'review_result' not in dir() or not review_result:\n        print(\"âš ï¸ Cell 6ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš” (ë¦¬ë·° ìƒì„±)\")\n    elif not GEMINI_API_KEY:\n        print(\"âš ï¸ Gemini API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤ (ë²ˆì—­ìš©)\")\n    else:\n        import google.generativeai as genai\n        \n        review_text = review_result.get('review', '')\n        if not review_text:\n            print(\"âš ï¸ ë²ˆì—­í•  ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤\")\n        else:\n            print(\"ğŸ”„ ë¦¬ë·° ë²ˆì—­ ì¤‘... (Gemini)\")\n            \n            genai.configure(api_key=GEMINI_API_KEY)\n            model = genai.GenerativeModel('gemini-2.5-flash')\n            \n            # ê°„ê²°í•œ ë²ˆì—­ í”„ë¡¬í”„íŠ¸\n            prompt = f\"\"\"ë‹¤ìŒ ì˜ì–´ ë…¼ë¬¸ ë¦¬ë·°ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”. \ní•™ìˆ ì  ì–´íˆ¬ë¥¼ ìœ ì§€í•˜ê³ , ì „ë¬¸ ìš©ì–´ëŠ” ì˜ì–´ë¥¼ ë³‘ê¸°í•˜ì„¸ìš”.\n\n---\n{review_text}\n---\n\ní•œêµ­ì–´ ë²ˆì—­:\"\"\"\n            \n            response = model.generate_content(prompt)\n            review_korean = response.text\n            \n            # ê²°ê³¼ ì €ì¥\n            review_result['review_korean'] = review_korean\n            \n            print(\"âœ… ë²ˆì—­ ì™„ë£Œ!\")\n            print(\"=\"*60)\n            print(review_korean[:2000])\n            if len(review_korean) > 2000:\n                print(f\"\\n... ({len(review_korean)}ì ì¤‘ 2000ìë§Œ í‘œì‹œ)\")\n            print(\"=\"*60)\nelse:\n    print(\"â„¹ï¸ í•œê¸€ ë²ˆì—­ì„ ì›í•˜ë©´ TRANSLATE_TO_KOREAN = True ë¡œ ì„¤ì •í•˜ì„¸ìš”\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: ê²°ê³¼ ì €ì¥ (JSON + Markdown)\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "if 'review_result' in dir() and review_result:\n",
    "    output_dir = os.path.join(WORKSHOP_DIR, \"outputs\", \"3_agent_result\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # review_resultëŠ” ë”•ì…”ë„ˆë¦¬ì„\n",
    "    result_dict = {\n",
    "        \"method\": \"agentic-paper-review\",\n",
    "        \"paper_path\": PAPER_PATH,\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"status\": review_result.get('status', 'unknown'),\n",
    "        \"paper_metadata\": review_result.get('paper_metadata', {}),\n",
    "        \"review\": review_result.get('review', ''),\n",
    "        \"scores\": review_result.get('scores', {}),\n",
    "        \"related_works\": review_result.get('related_works', []),\n",
    "        \"errors\": review_result.get('metadata', {}).get('errors', [])\n",
    "    }\n",
    "    \n",
    "    # 1. JSON ì €ì¥ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)\n",
    "    json_path = os.path.join(output_dir, f\"review_{timestamp}.json\")\n",
    "    with open(json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(result_dict, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # 2. Markdown ì €ì¥ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)\n",
    "    md_path = os.path.join(output_dir, f\"review_{timestamp}.md\")\n",
    "    \n",
    "    scores = result_dict.get('scores', {})\n",
    "    dimensions = scores.get('dimensions', [])\n",
    "    \n",
    "    md_content = f\"\"\"# AI Paper Review (agentic-paper-review)\n",
    "\n",
    "**ìƒì„± ì‹œê°„**: {result_dict['timestamp']}\n",
    "\n",
    "## ë…¼ë¬¸ ì •ë³´\n",
    "- **ì œëª©**: {result_dict.get('paper_metadata', {}).get('title', 'Unknown')}\n",
    "- **ìƒíƒœ**: {result_dict.get('status', 'unknown')}\n",
    "- **ìµœì¢… ì ìˆ˜**: {scores.get('final_score_display', 'N/A')}\n",
    "\n",
    "## ì ìˆ˜ ìƒì„¸\n",
    "\"\"\"\n",
    "    for dim in dimensions:\n",
    "        md_content += f\"- **{dim['name']}**: {dim['score']} - {dim['justification']}\\n\"\n",
    "    \n",
    "    md_content += f\"\"\"\n",
    "## ë¦¬ë·°\n",
    "{result_dict.get('review', 'ë¦¬ë·° ì—†ìŒ')}\n",
    "\n",
    "## ê´€ë ¨ ì—°êµ¬\n",
    "\"\"\"\n",
    "    for w in result_dict.get('related_works', []):\n",
    "        md_content += f\"- [{w['title']}](https://arxiv.org/abs/{w['arxiv_id']}) (ê´€ë ¨ë„: {w['relevance']:.2f})\\n\"\n",
    "    \n",
    "    with open(md_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(md_content)\n",
    "    \n",
    "    # ìµœì‹  ê²°ê³¼ë¥¼ review.jsonìœ¼ë¡œë„ ì €ì¥ (ë…¸íŠ¸ë¶ 4 ë¹„êµìš©)\n",
    "    latest_json = os.path.join(output_dir, \"review.json\")\n",
    "    with open(latest_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(result_dict, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"ğŸ’¾ ê²°ê³¼ ì €ì¥:\")\n",
    "    print(f\"   JSON: {json_path}\")\n",
    "    print(f\"   Markdown: {md_path}\")\n",
    "    print(f\"   (+ review.json ìµœì‹  ë²„ì „ ì—…ë°ì´íŠ¸)\")\n",
    "    print(f\"   ë¦¬ë·° ê¸¸ì´: {len(result_dict['review'])} ë¬¸ì\")\n",
    "    print(f\"   ì ìˆ˜: {scores.get('final_score_display', 'N/A')}\")\n",
    "else:\n",
    "    print(\"âš ï¸ ë¦¬ë·° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: ê²°ê³¼ ê³µìœ  ë° í† ë¡ \n",
    "\n",
    "### ê²°ê³¼ ì œì¶œ ë°©ë²•\n",
    "\n",
    "1. **ì•„ë˜ ì…€ì—ì„œ ì´ë¦„ ì…ë ¥**\n",
    "2. **ì…€ ì‹¤í–‰ â†’ íŒŒë€ ë²„íŠ¼ í´ë¦­**\n",
    "3. **í¼ì—ì„œ ì˜ê²¬ ì‘ì„± í›„ ì œì¶œ**\n",
    "\n",
    "> ì ìˆ˜ëŠ” ìë™ ì…ë ¥ë©ë‹ˆë‹¤!\n",
    "\n",
    "### ë§í¬\n",
    "\n",
    "| ìš©ë„ | ë§í¬ |\n",
    "|------|------|\n",
    "| **ì§ì ‘ ì œì¶œ** (ìë™ ì…ë ¥ ì•ˆ ë  ë•Œ) | [Google Forms](https://docs.google.com/forms/d/e/1FAIpQLSfciPtMCZTSNyGvutdFGSdcUjKSdu98Vm7gVPe6TvVcGQKK2g/viewform) |\n",
    "| **ê²°ê³¼ í™•ì¸** | [Google Sheet](https://docs.google.com/spreadsheets/d/1wPGTOPGF5yvWQTimikr-rg2VExXiHCE0Xn2EVkffWfo/edit?usp=sharing) |\n",
    "\n",
    "### í† ë¡  ì§ˆë¬¸\n",
    "\n",
    "1. **AI ë¦¬ë·°ê°€ ìœ ìš©í–ˆë‚˜ìš”?** (1-5ì )\n",
    "2. **ì–´ë–¤ ì ì´ ìœ ìš©í–ˆë‚˜ìš”?**\n",
    "3. **ì‹¤ì œ ë¦¬ë·°ì™€ ê³µí†µì **ì€?\n",
    "4. **ì‹¤ì œ ë¦¬ë·°ì™€ ì°¨ì´ì **ì€?\n",
    "5. **ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„**ì€?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 9: ê²°ê³¼ ì œì¶œ\n# ============================================================\n# ì´ë¦„ë§Œ ì…ë ¥í•˜ì„¸ìš”! ë‚˜ë¨¸ì§€ëŠ” ìë™ìœ¼ë¡œ ì±„ì›Œì§‘ë‹ˆë‹¤.\n# ============================================================\n\nPARTICIPANT_NAME = \"\"  # <- ë³¸ì¸ ì´ë¦„ ì…ë ¥\n\n# ============================================================\n# ì‹¤í—˜ ê²°ê³¼ ìë™ ìˆ˜ì§‘\n# ============================================================\nimport urllib.parse\nimport json\nfrom datetime import datetime\nfrom IPython.display import display, HTML\n\nif not PARTICIPANT_NAME:\n    print(\"âš ï¸  PARTICIPANT_NAMEì„ ì…ë ¥í•˜ì„¸ìš”!\")\nelif 'review_result' not in dir() or not review_result:\n    print(\"âš ï¸  Cell 6ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”! (ë¦¬ë·° ì‹¤í–‰)\")\nelse:\n    # ê²°ê³¼ ì¶”ì¶œ\n    scores = review_result.get('scores', {})\n    dimensions = scores.get('dimensions', [])\n    \n    # ì ìˆ˜ ì¶”ì¶œ\n    final_score = scores.get('final_score_display', '')\n    soundness = \"\"\n    presentation = \"\"\n    contribution = \"\"\n    \n    for dim in dimensions:\n        name = dim.get('name', '').lower()\n        score = str(dim.get('score', ''))\n        if 'sound' in name:\n            soundness = score\n        elif 'present' in name:\n            presentation = score\n        elif 'contribu' in name:\n            contribution = score\n    \n    # ì‚¬ìš©í•œ ë…¼ë¬¸ ìœ í˜•\n    paper_type = \"ìƒ˜í”Œ ë…¼ë¬¸\" if \"sample_manuscript\" in PAPER_PATH else \"ë³¸ì¸ ë…¼ë¬¸\"\n    \n    # Pre-filled Google Form URL ìƒì„±\n    FORM_BASE = \"https://docs.google.com/forms/d/e/1FAIpQLSfciPtMCZTSNyGvutdFGSdcUjKSdu98Vm7gVPe6TvVcGQKK2g/viewform?usp=pp_url\"\n    \n    params = {\n        \"entry.1176756138\": PARTICIPANT_NAME,  # ì´ë¦„\n        \"entry.1543210690\": paper_type,        # ì‚¬ìš©í•œ ë…¼ë¬¸\n        \"entry.538415097\": final_score,        # ìµœì¢… ì ìˆ˜\n        \"entry.233528916\": soundness,          # Soundness\n        \"entry.2053546740\": presentation,      # Presentation\n        \"entry.1438513897\": contribution,      # Contribution\n        # ë‚˜ë¨¸ì§€ëŠ” í¼ì—ì„œ ì§ì ‘ ì‘ì„±\n        # entry.620778037: AI ë¦¬ë·° ìœ ìš©ì„± (1-5)\n        # entry.1900039021: ì–´ë–¤ ì ì´ ìœ ìš©í–ˆë‚˜ìš”?\n        # entry.2048465412: ì‹¤ì œ ë¦¬ë·°ì™€ ê³µí†µì \n        # entry.1192534948: ì‹¤ì œ ë¦¬ë·°ì™€ ì°¨ì´ì \n        # entry.1803074178: ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„\n    }\n    \n    form_url = FORM_BASE + \"&\" + urllib.parse.urlencode(params)\n    \n    # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°\n    print(\"=\" * 70)\n    print(\"ğŸ“‹ ì œì¶œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°\")\n    print(\"=\" * 70)\n    print(f\"\\nğŸ‘¤ ì´ë¦„: {PARTICIPANT_NAME}\")\n    print(f\"ğŸ“„ ë…¼ë¬¸: {paper_type}\")\n    print(f\"\\nğŸ¯ ìµœì¢… ì ìˆ˜: {final_score}\")\n    print(f\"   Soundness: {soundness}\")\n    print(f\"   Presentation: {presentation}\")\n    print(f\"   Contribution: {contribution}\")\n    \n    # í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ ì¶œë ¥\n    print(\"\\n\" + \"=\" * 70)\n    print(\"ğŸ”— ì•„ë˜ ë²„íŠ¼ í´ë¦­ â†’ ì˜ê²¬ ì‘ì„± â†’ ì œì¶œ\")\n    print(\"=\" * 70)\n    \n    display(HTML(f'''\n    <a href=\"{form_url}\" target=\"_blank\" \n       style=\"display:inline-block; font-size:16px; padding:12px 24px; \n              background:#4285f4; color:white; text-decoration:none; \n              border-radius:5px; margin:10px 0;\">\n       ğŸ“ ê²°ê³¼ ì œì¶œí•˜ê¸° (í´ë¦­)\n    </a>\n    <p style=\"color:#666; font-size:12px;\">â€» ì ìˆ˜ëŠ” ìë™ ì…ë ¥ë©ë‹ˆë‹¤. ì˜ê²¬ë§Œ ì‘ì„±í•˜ì„¸ìš”!</p>\n    '''))\n    \n    # ë¡œì»¬ ë°±ì—… ì €ì¥\n    save_data = {\n        'participant': PARTICIPANT_NAME,\n        'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n        'paper_type': paper_type,\n        'scores': {\n            'final': final_score,\n            'soundness': soundness,\n            'presentation': presentation,\n            'contribution': contribution\n        },\n        'review': review_result.get('review', '')[:500]  # ì²˜ìŒ 500ìë§Œ\n    }\n    \n    if IN_COLAB:\n        save_folder = \"/content/drive/MyDrive/Hands-on-3/outputs/3_agent_result/\"\n    else:\n        save_folder = os.path.join(WORKSHOP_DIR, \"outputs\", \"3_agent_result\")\n    \n    os.makedirs(save_folder, exist_ok=True)\n    filename = f\"{PARTICIPANT_NAME}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n    filepath = os.path.join(save_folder, filename)\n    \n    with open(filepath, 'w', encoding='utf-8') as f:\n        json.dump(save_data, f, ensure_ascii=False, indent=2)\n    \n    print(f\"\\nâœ“ ë¡œì»¬ ë°±ì—…: {filepath}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì •ë¦¬\n",
    "\n",
    "### ì´ë²ˆ ë…¸íŠ¸ë¶ì—ì„œ ë°°ìš´ ê²ƒ\n",
    "\n",
    "1. **ê¸°ì¡´ ì˜¤í”ˆì†ŒìŠ¤ Paper Review Agent ë„êµ¬ë“¤** íƒìƒ‰\n",
    "   - agentic-paper-review, AgentReview, AI-Scientist\n",
    "2. **agentic-paper-review ì‹¤í–‰**: Python APIë¡œ ë…¼ë¬¸ ë¦¬ë·°\n",
    "3. **LangGraph ê¸°ë°˜ 9ë…¸ë“œ ì›Œí¬í”Œë¡œìš°** ì´í•´\n",
    "   - PDFâ†’MD â†’ ë©”íƒ€ë°ì´í„° â†’ ì¿¼ë¦¬ìƒì„± â†’ ì›¹ê²€ìƒ‰ â†’ ê´€ë ¨ì„±í‰ê°€ â†’ ë¦¬í”Œë ‰ì…˜ â†’ ìš”ì•½ â†’ ë¦¬ë·°ìƒì„± â†’ ì ìˆ˜ì‚°ì •\n",
    "4. **ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ ì§€ì›**: PDF, MD, TXT, DOCX\n",
    "\n",
    "### ë‹¤ìŒ ë…¸íŠ¸ë¶ ì˜ˆê³ \n",
    "\n",
    "- **Notebook 4**: ì§ì ‘ ë¦¬ë·° ì—ì´ì „íŠ¸ êµ¬í˜„ & ê²°ê³¼ ë¹„êµ\n",
    "\n",
    "### ì°¸ê³  ìë£Œ\n",
    "\n",
    "- agentic-paper-review: https://github.com/debashis1983/agentic-paper-review\n",
    "- AgentReview Paper: https://arxiv.org/abs/2406.12708\n",
    "- LangGraph Docs: https://python.langchain.com/docs/langgraph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}